## 인공지능의 분류
- 강인공지능(Strong/General AI)
    - SF 영화의(자아를 가진) AI 로봇들
    - 다양한 분야에서 보편적으로 활용이 가능함
    - 알고리즘을 설계하면 AI가 스스로 데이터를 찾아 학습
    - 정해진 규칙을 벗어나 능동적으로 학습해 창조가 가능함
    
<br>

- 약인공지능(Weak/Narrow AI)
    - 현재 산업에서 사용되는 AI 프로그램
    - 한가지 분야만 잘하므로, 특정 분야에서만 활용이 가능
    - 알고리즘은 물론, 기초 데이터, 규칙을 입력해야함
    - 이를 바탕으로 학습이 가능. 규칙을 벗어난 창조는 불가능

> 사람이 교육방법/환경에 따라 달라지듯, AI도 학습방법에 따라 성능이 달라진다.

<br><br>

## 머신러닝(Machine Learning)
- 사람이 학습하듯 컴퓨터에게 사람이 데이터를 입력시켜 학습을 시키는 방식
- input -> 학습 -> output
- 데이터들을 -> 학습(분석/분류)해서 -> 모델(결과물)을 뽑아낸다.

<br>

**머신러닝의 종류**
- 지도학습(supervised)
- 비지도학습(Unsupervised)
- 강화학습(Reinforcement Learning)

<br>

**지도 학습(supervised)** 
- 정답을 알려주며 학습시키는 것
- 지도 학습에는 크게 `분류(classification)` `회귀(regression)`가 있다.

<br>

- 회귀(Regression)
    - 데이터들의 특징을 기준으로 연속된 값을 예측하는 방법.
    - 결과 값은 실수값을 가질 수 있다. (그 값들은 연속성을 가짐. 그래프를 생각해보자.)
    ex) Q: 어디 동네에 어떤 평수 아파트이면 집 값이 얼마정도야?
        A: 어디 동네에 32평이면 얼마, 45평이면 얼마야

<br>

- 분류(Classification)
    - 데이터를 정해진 라벨에 따라 분류하는 방법.
    - 두가지 선택지의 이전 분류와 그 이상의 선택지를 가진 다중 분류가 존재
        - 이진 분류 : 어떤 데이터에 대해 두 가지 중 하나로 분류할 수 있는 것
        ex) Q: 이 글은 스팸이야?
            A: 예 또는 아니오
        
        - 다중 분류 : 어떤 데이터에 대해 여러 값 중 하나로 분류할 수 있는 것
        ex) Q: 이 동물은 뭐야?
            A: 고양이 또는 사자 또는 강아지 등..
    
<br>
    
**비지도 학습(Unsupervised)**

정답을 알려주지 않고, 비슷한 데이터들을 군집화 하는 것.

예를들어, 고양이, 병아리, 기린, 호랑이 사진을 비지도 학습 시키려면, 각 사진이 무엇인지 알려주지 않았기 때문에 비슷한 단위로 군집화를 한다.<br>

다리가 4개인 고양이와 호랑이를 한 분류로 묶고, 다리가 4개이지만 목이 긴 기린은 다른 분류로, 다리가 2개이며 몸통이 둥그런 병아리는 또 다른 분류로 나누어 놓는다.<br>

<br>

**강화 학습(Reinforcement Learning)**

상과 벌이라는 보상(reward)을 주며 상을 최대화하고, 벌을 최소화 하도록 강화 학습하는 방식이다. 알파고도 이 방법으로 학습되었으며, 주로 게임에서 최적의 동작을 찾는데 쓰이는 학습방식이다. 우리들의 인생도 강화학습이라고 볼 수 있다.

태어나서 지금까지 우리는 이러한 저러한 행동들을 해왔고, 내가 하는 행동으로 인해 누군가에게 칭찬을받거나 질책을 받아왔다.
이런저런 시행착오를 겪으며 경험을 쌓아왔고, 내가 확실히 경함한 것에 대해서는 들은것보다 더 옳고 그른지 판단을 할 수 있다.<br>

하지만 여전히 경험해보지 못한 부분에 대해서는 칭찬을 받기도 하며, 질책을 받기도 한다.
정확한 답은 없지만, 이러한 반복들을 통하여 칭찬과 질책을 받으며 보상의 가중치를 최대화 하는 것이 목표인 학습 방식이다.


<br><br>


### ANN(Artificial Neural Network) - 인공 신경망성
- 모든 비선형 함수를 학습
- 학습과정에서 피라미터 최적값 찾기가 어려움
- Overfitting에 따른 문제

<br>

### SLP(Single Layer Perceptron) - 단층 퍼셉트론
- 퍼셉트론 : 학습 능력을 갖는 패턴분류 장치
- 단일 퍼셉트론으로 구성

<br>    

### MLP(Multi Layer Perceptron) - 다중 퍼셉트론
- 여러층의 퍼셉트론으로 적어도 1개 이상의 은닉층(hidden layer) 보유
- 일반적으로 지도학습
- 역전파 알고리즘(Backpropagation)으로 학습 - 다층 퍼셉트론 문제 해결을 위한 알고리즘
- 경사 하강법으로 에러를 최소화

<br>
    
### DNN(Deep Neural Network) - 심층신경망
- ANN 문제를 해결하기 위해 은닉층을 확대
- 2개 이상의 은닉층으로 학습(보통 Deep Learning은 3개 이상)
- DNN을 응용하여 CNN, RNN, LSTM, GRU 발전
    
<br>
    
### RNN(Recurrent Neural Network) - 순환신경망
- RNN은 입력 데이터에 있는 순처 정보 캡처
    
<br>
    
### CNN(Convolution Neural Network) - 콘볼루션신경망, 합성곱신경망
- 정보추출, 문장분류, 얼굴인식 등 널리 사용. 특히 이미지 및 비디오 처리에 활용
- 핵심 요소는 커널(콘볼루션 연산을 사용하여 입력에서 관련 기능 추출)이라는 필터
- 암시적으로 필터를 자동으로 학습(입력 데이터에서 올바른 관련 기능 추출에 도움)
- 입력 데이터의 특징을 추출하여 특징들의 패턴 파악하는 구조
- Convolution 과정과 Pooling 과정으로 진행   
    
![다양한 신경망 비교](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcEZJBF%2FbtqNpGOj3Ob%2Fzj6suBvXW1kK0IKy5SoEwk%2Fimg.png)

<br><br>

### 상위층, 하위
기본 CNN 기반에서, `하위층`은 어느정도 일반적이고 재사용성이 있는 특성을 학습하며, `상위층`은 좀 더 구체적인 특성을 학습함. (고양이 귀, 눈, 코 등)<br>
따라서, 미세조정(fine tuning) 시에는 상위층을 나의 데이터에 맞게 조절하는 거시 좋다. (하위층으로 갈수록 fine tuning의 효과가 감소)

<br>

### 파라미터(Parameter)
- 파라미터는 한국말로 `매개변수`이다.
- 파라미터는 모델 내부에서 결정되는 `변수`이다.
- 그 값은 데이터로부터 결정된다.

### 하이퍼 파라미터(Hyper Parameter)
- 하이퍼 파라미터는 모델링할 때 사용자가 직접 세팅해주는 값을 뜻한다.
- 즉, 머신러닝 모델을 쓸 때 사용자가 직접 세팅해야 하는 모든 값들이 하이퍼 파라미터이다.

> 파라미터와 하이퍼 파라미터를 구분하는 기준은, `"사용자가 직접 설정하느냐 아니냐"`의 차이이다. 
> 사용자가 직접 설정하면 `하이퍼 파라미터`, 모델 혹은 데이터에 의해 결졍되면 `파라미터`이다.

<br>

### 최적화(Optimization)
- 가능한 훈련 데이터에서 최고의 성능을 얻으려고 모델을 조절하는 과정

### 일반화(Generalization)
- 훈련된 모델이 이전에 본적없는 데이터에서 얼마나 잘 수행되는지 의미

<br>

### Fine Turning(미세조정)
- 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고, 이미 학습된 모델 Weights로 부터 학습을 업데이트 하는 방법
- 모델의 파라미터를 미세하게 조정하는 행위
- 파인튜닝은 정교한 파라미터 튜닝이라고 생각하면 되는데 `정교한`과 `파라미터`가 키포인트이다.

<br>

### Sequential API와 Functional API 차이점
- functional api 에서는 입력 데이터의 크기(shape)를 Input() 함수의 인자로 입력층을 정의해주어야 한다.
- 이전층을 다음층 함수의 입력으로 사용하고, 변수에 할당해야함
- Model() 함수에 입력과 출력을 정

<br>

### 퍼셉트론
- 퍼셉트론은 다수의 신호(Input)를 입력받아서 하나의 신호(Output)를 출력한다.
- 뉴런의 수상돌기나 축색돌기처럼 신호를 전달하는 역할을 퍼셉트론에서는 weight(가중치)가 그 역할을 한다.
- weight는 각각의 입력신호에 부여되어 입력신호와의 계산을 하고 신호의 총합이 정해진 임계값을 넘었을 때 1을 출력한다. 넘지 못하면 0 또는 -1을 출력한다.

<br> 
